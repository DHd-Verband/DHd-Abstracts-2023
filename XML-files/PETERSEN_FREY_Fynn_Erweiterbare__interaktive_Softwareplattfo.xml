<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:id="PETERSEN_FREY_Fynn_Erweiterbare__interaktive_Softwareplattfo" xmlns="http://www.tei-c.org/ns/1.0">
    <teiHeader>
        <fileDesc>
            <titleStmt>
                <title type="full">
                    <title type="main">Erweiterbare, interaktive Softwareplattform für die Anwendung von Sprachtechnologie in großen Textkorpora zur Unterstützung von Such- und Analyseworkflows in den Digital Humanities</title>
                    <title type="sub"/>
                </title>
                <author>
                    <persName>
                        <surname>Petersen-Frey</surname>
                        <forename>Fynn</forename>
                    </persName>
                    <affiliation>Universität Hamburg, Deutschland</affiliation>
                    <email>fynn.petersen-frey@uni-hamburg.de</email>
                    <idno type="ORCID">0000-0001-6450-8100</idno>
                </author>
            </titleStmt>
            <editionStmt>
                <edition>
                    <date>2022-08-02T14:14:29.430363668</date>
                </edition>
            </editionStmt>
            <publicationStmt>
                    <publisher>Culture and Computation Lab</publisher>
                    <address>
                        <addrLine>Université du Luxembourg</addrLine>
                        <addrLine>2, Avenue de l'Université</addrLine>
                        <addrLine>L-4365 Esch-sur Alzette</addrLine>
                        <addrLine>Luxembourg</addrLine>
                    </address>
                    <publisher>Luxembourg Centre for Contemporary and Digital History</publisher>
                    <address>
                        <addrLine>Université du Luxembourg</addrLine>
                        <addrLine>2, Avenue de l'Université</addrLine>
                        <addrLine>L-4365 Esch-sur Alzette</addrLine>
                        <addrLine>Luxembourg</addrLine>
                    </address>
                    <publisher>Trier Center for Digital Humanities</publisher>
                    <address>
                        <addrLine>Universität Trier</addrLine>  
                        <addrLine>Universitätsring 15</addrLine>
                        <addrLine>54296 Trier</addrLine>
                        <addrLine>Deutschland</addrLine>
                    </address>
                </publicationStmt>
            <sourceDesc>
                <p>Converted from an OASIS Open Document</p>
            </sourceDesc>
        </fileDesc>
        <encodingDesc>
            <appInfo>
                <application ident="DHCONVALIDATOR" version="1.22">
                    <label>DHConvalidator</label>
                </application>
            </appInfo>
        </encodingDesc>
        <profileDesc>
            <textClass>
                <keywords scheme="ConfTool" n="category">
                    <term>Paper</term>
                </keywords>
                <keywords scheme="ConfTool" n="subcategory">
                    <term>Doctoral Consortium</term>
                </keywords>
                <keywords scheme="ConfTool" n="keywords">
                    <term>Software</term>
                    <term>Plattform</term>
                    <term>NLP</term>
                    <term>Sprachtechnologie</term>
                    <term>Text</term>
                    <term>Digital Humanities</term>
                    <term>Annotation</term>
                    <term>Kodierung</term>
                    <term>Suche</term>
                    <term>Embeddings</term>
                </keywords>
            </textClass>
        </profileDesc>
    </teiHeader>
    <text>
        <body>
            <div type="div1" rend="DH-Heading">
                <head>Motivation und Einleitung</head>
                <p>In Wissenschaftsdisziplinen wie den digitalen Geistes- und Sozialwissenschaften „Digital Humanities“ (DH), besteht ein großes Interesse daran, umfangreiche Mengen von Text, z.B. aus historischen Zeitschriften (Purschwitz 2018, 109–142), sozialen Medien (Stier u. a. 2017, 1365–1388) oder Zeitungen, hinsichtlich verschiedener Fragestellungen auszuwerten. Dabei ist oft eine Kombination von qualitativen Analyseschritten mit quantitativen Auswertungen gefragt (Stulpe und Lemke 2016, 17–61).</p>
                <p>Eine ausschließlich manuelle Bearbeitung ist angesichts des Umfangs und des daraus resultierenden Aufwands oftmals ausgeschlossen. In diesen Fällen ermöglicht es eine (teil-)automatisierte computerlinguistische Verarbeitung dennoch Analyse und Auswertung durchzuführen.</p>
                <p>Ziel dieses Dissertationsvorhabens ist es daher geeignete Methoden zu entwickeln und in eine moderne Sprachtechnologieplattform zu integrieren, die es Wissenschaftlern aus den DH ermöglicht, selbstständig große Textkorpora mit Hilfe (teil-)automatischer Verarbeitungsschritte aus der CL vorzubereiten und hinsichtlich vielfältiger Fragestellungen auszuwerten. Dies umfasst lexikalische wie semantische Suchfunktionen, intuitive Annotationsfunktionen, AI- bzw. Human-in-the-Loop Funktionalitäten zur (teil-)automatischen Skalierung von Annotationen auf große Korpora, über klassische syntaktische Anreicherungen hinausgehende inhaltliche NLP-Methoden wie Koreferenzausflösung und Zitaterkennung sowie qualitative und quantitative Analysemöglichkeiten.</p>
            </div>
            <div type="div1" rend="DH-Heading">
                <head>Forschungsstand</head>
                <p>Verwandte Software aus der Computerlinguistik wie 
                    <hi rend="italic">brat</hi> (Stenetorp u. a. 2012, 102–107), 
                    <hi rend="italic">WebAnno</hi> (Eckart de Castilho u. a. 2016, 76–84), 
                    <hi rend="italic">INCEpTION</hi> (Klie u. a. 2018, 5–9) oder 
                    <hi rend="italic">TextAnnotator</hi> (Abrami u. a. 2020, 891–900) sind vorrangig für linguistische Annotationen gedacht, um annotierte Korpora zu erstellen; weniger jedoch für die inhaltliche Bearbeitung einer DH-Forschungsfrage mittels Suche, Annotation, Aggregation und Analyse.
                </p>
                <p>Für spezifische Recherchezwecke existieren computerlinguistische Anwendungen wie 
                    <hi rend="italic">SiNLP</hi> (Crossley u. a. 2014, 511–534) zur Diskursanalyse, 
                    <hi rend="italic">ALCIDE</hi> (Moretti u. a. 2016, 100–112) zur Analyse von historischem und politischem Diskurs, 
                    <hi rend="italic">new/s/leak</hi> (Wiedemann u. a. 2018, 313–322) zum Entdecken berichtenswerter Geschehnisse in großen Textkorpora sowie 
                    <hi rend="italic">LawStats</hi> (Ruppert u. a. 2018, 212–222) zur Suche und Analyse von Revisionen des Bundesgerichtshofs. Diese Anwendungen sind jedoch weniger geeignet andere Fragestellungen zu bearbeiten.
                </p>
                <p>In den Sozialwissenschaften gängige qualitative Analysetools wie 
                    <hi rend="italic">MaxQDA</hi> oder 
                    <hi rend="italic">atlas.ti</hi> verfügen über Annotations- und qualitative Analysefunktionen, sind aber proprietär, erlauben kaum Kollaboration und bieten keine modernen NLP-Methoden.
                </p>
                <p>
                    <hi rend="italic">Recogito</hi> (Simon u. a. 2017, 111–132) und 
                    <hi rend="italic">CATMA</hi> (Gius u. a., 2022) sind intuitive Annotationsanwendungen für die DH mit Kollaborationsfunktionen. 
                    <hi rend="italic">Recogito </hi>setzt 
                    <hi rend="italic">e</hi>inen Fokus auf Orte und Integration in eine Karte mittels automatischer Erkennung von Entitäten. 
                    <hi rend="italic">CATMA</hi> bietet konfigurierbare Annotationsschemata und vielfältige Analysefunktionen. Beide verfügen jedoch nur über eine bescheidene bzw. keine Suche, wenig Unterstützung für große Korpora und keine Möglichkeit zur Skalierung manueller Annotationen.
                </p>
                <p>
                    <hi rend="italic">WebLicht</hi> (Hinrichs u. a. 2010, 25–29) integriert enorm viele NLP-Module, die zu individuellen Pipelines zusammengefügt werden können.
                    <hi rend="italic"> </hi>
                    <hi rend="italic">Nopaque</hi> (Universität Bielefeld 2022) unterstützt historische Dokumente mittels OCR und syntaktische Analysen anhand Keyword-In-Context-Suche auf Basis
                    <hi rend="italic"> </hi>gängiger NLP-Modelle und individueller NLP-Pipelines. Beiden fehlen jedoch Annotationsmöglichkeiten, Kollaborationsfunktionen, Dokumentensuche sowie Möglichkeiten zur quantitativen Analyse großer Korpora.
                </p>
                <p>
                    <hi rend="italic">ILCM</hi> (Niekler u. a. 2018, 1313–1319) ist eine Textmining-Umgebung für die datengetriebene Forschung auf der großen Textmengen mittels statistischer Analysen. Es fehlen jedoch moderne NLP-Modelle sowie interaktive Funktionalitäten wie Annotation oder Suche.
                </p>
            </div>
            <div type="div1" rend="DH-Heading">
                <head>Forschungsvorhaben und Forschungsfragen</head>
                <p>Das Forschungsvorhaben steht unter der übergreifenden Forschungsfrage: Wie kann eine digitale Arbeitsumgebung entwickelt werden, welche undogmatisch die Anwendung von DH-Methoden durch moderne NLP-Methoden für Suche, Annotation, Skalierung, Aggregation und Analyse auf großen Korpora unterstützt?</p>
                <p>Das Ziel ist es geeignete Methoden für eine Sprachtechnologieplattform zu entwerfen, die intuitiv aus den DH genutzt werden kann, um manuelle Arbeit mit Textdokumenten automatisch auf große Korpora zu skalieren. Dies umfasst u. a. eine semantischen Suche um ähnliche Aussagen zu einer bestimmten Textpassage im gesamten Korpus zu finden, die Möglichkeit gefundenen Textpassagen qualitativ manuell zu analysieren oder automatisch zu aggregieren für quantitative Auswertungen. Im Zusammenspiel von Entity-Linking, Koreferenzauflösung, Zitaterkennung und Auffinden ähnlicher Textpassagen soll eine Skalierung manueller Annotation bzw. Kodierung von Textspannen auf den gesamten Korpus ermöglicht werden, indem Annotationen einzelner Textstellen auf passende Stellen gesamten Korpus angewandt wird.</p>
                <p>Wie können dem aktuellen Stand der Forschung entsprechende computerlinguistische Methoden undogmatisch und intuitiv für die Bearbeitung verschiedener DH-Fragestellungen nutzbar gemacht werden?</p>
                <p>Zum aktuellen Stand der Forschung zählen kontextualisierte Embeddings wie 
                    <hi rend="italic">BERT</hi> (Devlin u. a. 2019, 4171–4186), die jedem Wort und (Ab-)Satz eine Bedeutung in Abhängigkeit des Kontexts anhand der Position in einem hochdimensionalen Vektorraum zuordnen. Wie lässt sich auf dieser Basis eine semantische Ähnlichkeitssuche zum Auffinden verwandter Aussagen mit variierender Länge entwickeln? Dabei ist zu klären, welche Lösungen für die rechenintensiven Operationen bei der Ähnlichkeitssuche mit großen Korpora skalieren.
                </p>
                <p>Um diese NLP-Methoden nutzbar zu machen, werden sie in eine webbasierte Benutzeroberfläche integriert, die das Durchsuchen, Annotieren, Skalieren, Aggregieren und Auswerten großer Korpora mittels der zuvor beschriebenen computerlinguistischen Funktionalitäten unterstützt. Ferner wird geeignete Softwarearchitektur entworfen, welche die Integration bestehender und zukünftiger CL-Softwarebibliotheken ermöglicht.</p>
            </div>
        </body>
        <back>
            <div type="bibliogr">
                <listBibl>
                    <head>Bibliographie</head>
                    <bibl>
                        <hi rend="bold">Abrami, Giuseppe, Manuel Stoeckel und Alexander Mehler.</hi> 2020. “TextAnnotator: A UIMA Based Tool for the Simultaneous and Collaborative Annotation of Texts”. English. In: 
                        <hi rend="italic">Proceedings of The 12th Language Resources and Evaluation Conference</hi>. Marseille, France: European Language Resources Association, S. 891–900. isbn: 979-10-95546-34-4. url: https://www.aclweb.org/anthology/2020.lrec-1.112.
                    </bibl>
                    <bibl>
                        <hi rend="bold">Crossley, Scott A., Laura K. Allen, Kristopher Kyle und Danielle S. McNamara.</hi> 2014. “Analyzing Discourse Processing Using a Simple Natural Language Processing Tool”. In: 
                        <hi rend="italic">Discourse Processes 51.5-6</hi>, S. 511–534. doi: 10.1080/0163853X.2014.910723.
                    </bibl>
                    <bibl>
                        <hi rend="bold">Devlin, Jacob, Ming-Wei Chang, Kenton Lee und Kristina Toutanova.</hi> 2019. “BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding”. In: 
                        <hi rend="italic">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</hi>. Minneapolis, Minnesota: Association for Computational Linguistics, S. 4171–4186. doi: 10.18653/v1/N19- 1423. url: https://www.aclweb.org/anthology/N19-1423.
                    </bibl>
                    <bibl>
                        <hi rend="bold">Eckart de Castilho, Richard, Éva Mújdricza-Maydt, Seid Muhie Yimam, Silvana Hartmann, Iryna Gurevych, Anette Frank und Chris Biemann.</hi> 2016. “A Web-based Tool for the Integrated Annotation of Semantic and Syntactic Structures”. In: 
                        <hi rend="italic">Proceedings of the Workshop on Language Technology Resources and Tools for Digital Humanities (LT4DH)</hi>. Osaka, Japan: The COLING 2016 Organizing Committee, S. 76–84. url: https://www.aclweb.org/anthology/W16-4011.
                    </bibl>
                    <bibl>
                        <hi rend="bold">Gius, Evelyn, Jan Christoph Meister, Malte Meister, Marco Petris, Christian Bruck, Janina Jacke, Mareike Schumacher, Dominik Gerstorfer, Marie Flüh, </hi>
                        <hi rend="bold">und</hi>
                        <hi rend="bold"> Jan Horstmann.</hi> 2022. “CATMA”. Zenodo, url: https://doi.org/10.5281/zenodo.6419805.
                    </bibl>
                    <bibl>
                        <hi rend="bold">Hinrichs, Erhard W., Marie Hinrichs and Thomas Zastrow.</hi> 2010. “WebLicht: Web-Based LRT Services for German”. In: Proceedings of the ACL 2010 System Demonstrations. S. 25–29. url: http://www.aclweb.org/anthology/P10-4005
                    </bibl>
                    <bibl>
                        <hi rend="bold">Klie, Jan-Christoph, Michael Bugert, Beto Boullosa, Richard Eckart de Castilho und Iryna Gurevych.</hi> 2018. “The INCEpTION Platform: Machine-Assisted and Knowledge-Oriented Interactive Annotation”. In: 
                        <hi rend="italic">Proceedings of the 27th International Conference on Computational Linguistics: System Demonstrations. Association for Computational Linguistics</hi>, S. 5–9. url: http://tubiblio.ulb.tu-darmstadt.de/106270/.
                    </bibl>
                    <bibl>
                        <hi rend="bold">Moretti, Giovanni, Rachele Sprugnoli, Stefano Menini und Sara Tonelli.</hi> 2016. “ALCIDE: Extracting and visualising content from large document collections to support humanities studies”. In: 
                        <hi rend="italic">Knowledge-Based Systems 111</hi>, S. 100–112. issn: 0950-7051. doi: https://doi.org/10.1016/j.knosys.2016.08.003. url: http://www.sciencedirect.com/science/article/pii/S0950705116302635.
                    </bibl>
                    <bibl>
                        <hi rend="bold">Niekler, Andreas, Arnim Bleier, Christian Kahmann, Lisa Posch, Gregor Wiedemann, Kenan Erdogan, Gerhard Heyer und Markus Strohmaier.</hi> 2018. “ILCM - A Virtual Research Infrastructure for Large-Scale Qualitative Data”. In: 
                        <hi rend="italic">Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018)</hi>. Miyazaki, Japan: European Language Resources Association (ELRA), S. 1313–1319 url: https://www.aclweb.org/anthology/L18-1209.
                    </bibl>
                    <bibl>
                        <hi rend="bold">Purschwitz, A.</hi> (2018). “Netzwerke des Wissens – Thematische und personelle Relationen innerhalb der halleschen Zeitungen und Zeitschriften der Aufklärungsepoche (1688-1818)”. In: 
                        <hi rend="italic">Journal of Historical Network Research</hi> 2 (1), S. 109–142.
                    </bibl>
                    <bibl>
                        <hi rend="bold">Ruppert, Eugen, Dirk Hartung, Phillip Sittig, Tjorben Gschwander, Lennart Rönneburg, Tobias Killing und Chris Biemann.</hi> 2018. LawStats – Large-Scale German Court Decision Evaluation Using Web Service Classifiers. In: 
                        <hi rend="italic">Machine Learning and Knowledge Extraction: Second IFIP TC 5, TC 8/WG 8.4, 8.9, TC 12/WG 12.9 International Cross-Domain Conference, CD-MAKE 2018</hi>, Hamburg, Germany, August 27–30, 2018, Proceedings. Springer-Verlag, Berlin, Heidelberg, 212–222. doi: 10.1007/978-3-319-99740-7_14
                    </bibl>
                    <bibl>
                        <hi rend="bold">S</hi>
                        <hi rend="bold">imon, Rainer, Elton Barker, Leif Isaksen </hi>
                        <hi rend="bold">und</hi>
                        <hi rend="bold"> Pau De Soto CaÑamares.</hi> 2017. “Linked Data Annotation Without the Pointy Brackets: Introducing Recogito 2”. In: Journal of Map &amp; Geography Libraries, 13:1, S. 111–132. doi: 10.1080/15420353.2017.1307303
                    </bibl>
                    <bibl>
                        <hi rend="bold">Stenetorp, Pontus, Sampo Pyysalo, Goran Topić, Tomoko Ohta, Sophia Ananiadou und Jun’ichi Tsujii.</hi> 2012. “brat: a Web-based Tool for NLP-Assisted Text Annotation”. In: 
                        <hi rend="italic">Proceedings of the Demonstrations at the 13th Conference of the European Chapter of the Association for Computational Linguistics</hi>. Avignon, France: Association for Computational Linguistics, S. 102–107. url: https://www.aclweb.org/anthology/E12-2021.
                    </bibl>
                    <bibl>
                        <hi rend="bold">Stier, Sebastian, Lisa Posch, Arnim Bleier und Markus Strohmaier.</hi> 2017. “When populists become popular: comparing Facebook use by the right-wing movement Pegida and German political parties”. In: 
                        <hi rend="italic">Information, Communication &amp; Society</hi> 20, S. 1365–1388. doi: 10.1080/1369118X.2017.1328519.
                    </bibl>
                    <bibl>
                        <hi rend="bold">Stulpe, Alexander und Matthias Lemke.</hi> 2016. “Blended Reading”. In: 
                        <hi rend="italic">Text Mining in den Sozialwissenschaften: Grundlagen und Anwendungen zwischen qualitativer und quantitativer Diskursanalyse</hi>. Hrsg. von Matthias Lemke und Gregor Wiedemann. Wiesbaden: Springer Fachmedien Wiesbaden, S. 17–61. isbn: 978-3-658-07224-7. doi: 10.1007/978-3-658-07224-7_2. url: https://doi.org/10.1007/978-3-658-07224-7_2.
                    </bibl>
                    <bibl>
                        <hi rend="bold">Wiedemann, Gregor, Seid Muhie Yimam und Chris Biemann. </hi>2018. “New/s/leak 2.0 – Multilingual Information Extraction and Visualization for Investigative Journalism”. In: 
                        <hi rend="italic">Social Informatics</hi>. Hrsg. von Steffen Staab, Olessia Koltsova und Dmitry I. Ignatov. Cham: Springer International Publishing, S. 313–322. isbn: 978-3-030-01159-8.
                    </bibl>
                    <bibl>
                        <hi rend="bold">Universität Bielefeld.</hi> 2022. “nopaque”. https://nopaque.uni-bielefeld.de (zugegriffen 12. Dezember 2022)
                    </bibl>
                </listBibl>
            </div>
        </back>
    </text>
</TEI>
